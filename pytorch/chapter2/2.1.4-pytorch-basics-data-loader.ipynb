{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 基础 :数据的加载和预处理\n",
    "\n",
    "PyTorch通过**torch.utils.data**对常用数据加载进行封装，可以容易地实现多线程**数据预读和批量加载**。\n",
    "\n",
    "torchvision已经预先实现常用图像数据集，包括CIFAR-10，ImageNet、COCO、MNIST、LSUN等，\n",
    "可通过torchvision.datasets方便调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 首先要引入相关的包\n",
    "import torch\n",
    "\n",
    "#打印一下版本\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Dataset是一个抽象类，为了能够方便读取，需要将要用的数据包装为Dataset类。\n",
    "\n",
    "自定义的Dataset需要继承它并且实现两个成员方法：\n",
    "1. `__getitem__()` 定义用索引(`0` 到 `len(self)`)获取一条数据或一个样本\n",
    "2. `__len__()` 返回数据集的总长度\n",
    "\n",
    "用kaggle上的一个竞赛[bluebook for bulldozers](https://www.kaggle.com/c/bluebook-for-bulldozers/data)自定义一个数据集，为了方便介绍，使用数据字典来做说明（因为条数少）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引用\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 定义一个数据集\n",
    "class BulldozerDataset(Dataset):\n",
    "    \"\"\" \n",
    "    数据集演示 \n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"\n",
    "        实现初始化方法，初始化时将数据读载入\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        返回df的长度\n",
    "        '''\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        根据 idx 返回一行数据\n",
    "        '''\n",
    "        return self.df.iloc[idx].SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，数据集已经定义完成，可以实例化一个对象访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_demo = BulldozerDataset('median_benchmark.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以直接使用如下命令查看数据集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11573"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实现了 __len__ 方法，所以可以直接用len获取数据总数\n",
    "len(ds_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用索引直接访问对应的数据，对应 __getitem__ 方法\n",
    "ds_demo[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义的数据集已经创建好，下面使用官方提供的数据载入器读取数据\n",
    "\n",
    "## Dataloader\n",
    "\n",
    "DataLoader提供对Dataset的读取操作，常用参数有：\n",
    "* **batch_size** (每个batch的大小)\n",
    "* **shuffle** (是否进行shuffle操作)\n",
    "* **num_workers** (加载数据时用几个子进程)\n",
    "\n",
    "下面做一个简单的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(ds_demo,\n",
    "                                 batch_size=10,\n",
    "                                 shuffle=True,\n",
    "                                 num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader返回一个**可迭代对象**，可以用迭代器分次获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.,\n",
      "        24000.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "idata = iter(dl)\n",
    "print(next(idata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常见用法是用for循环进行遍历"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.,\n",
      "        24000.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dl):\n",
    "    print(i, data)\n",
    "\n",
    "    # 为了节约空间，这里只循环一遍\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经可以通过dataset定义数据集，使用Datalorder载入和遍历数据集，\n",
    "\n",
    "除了这些，PyTorch还提供torcvision的计算机视觉扩展包，里面封装了\n",
    "\n",
    "## torchvision 包\n",
    "torchvision 是PyTorch专门处理图像的库，PyTorch官网的安装教程最后的pip install torchvision 就是安装这个包。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision.datasets\n",
    "torchvision.datasets 可以理解为PyTorch团队自定义的dataset，\n",
    "\n",
    "这些dataset提前处理好了很多的图片数据集，拿来可以直接使用：\n",
    "\n",
    "- MNIST\n",
    "- COCO\n",
    "- Captions\n",
    "- Detection\n",
    "- LSUN\n",
    "- ImageFolder\n",
    "- Imagenet-12\n",
    "- CIFAR\n",
    "- STL10\n",
    "- SVHN\n",
    "- PhotoTour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8e1707149b43d8935fc7199e850b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4218feee5cc046edad09c1bee523e4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e3c2159887435f9db8c7398548e4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14e3ad7eec44ee4922643ff180b6bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinminyu/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "trainset = datasets.MNIST(\n",
    "    # MNIST 数据的加载目录\n",
    "    root='./data',\n",
    "    \n",
    "    # 是否加载数据库的训练集，false加载测试集\n",
    "    train=True,\n",
    "    \n",
    "    # 是否自动下载 MNIST 数据集\n",
    "    download=True,\n",
    "    \n",
    "    # 是否需要对数据进行预处理，none为不进行预处理\n",
    "    transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision.models\n",
    "\n",
    "torchvision不仅提供常用图片数据集，还提供训练好的模型，加载后可以直接使用，或者进行迁移学习\n",
    "torchvision.models的子模块包含以下模型结构。\n",
    "- AlexNet\n",
    "- VGG\n",
    "- ResNet\n",
    "- SqueezeNet\n",
    "- DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/jinminyu/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c711764677347fe97e1431b225afbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 可以直接使用训练好的模型，这个与datasets相同，都需要从服务器下载\n",
    "import socket\n",
    "socket.gethostbyname(\"\")\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision.transforms\n",
    "transforms 模块提供一般的图像转换操作类，用作数据处理和数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    #四周填充0，把图像随机裁剪成32*32\n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    \n",
    "    #图像一半概率翻转，一半概率不翻转\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    \n",
    "    #随机旋转\n",
    "    transforms.RandomRotation((-45, 45)),  \n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    #R,G,B每层的归一化用到的均值和方差\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.229, 0.224, 0.225)),  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.4914, 0.4822, 0.4465), (0.229, 0.224, 0.225)这几个数字是什么意思？\n",
    "\n",
    "官方的这个帖子有详细的说明:\n",
    "https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/21\n",
    "这是根据ImageNet训练的归一化参数，可以直接使用，认为这个是固定值就可以"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
