{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 logistic回归实战\n",
    "\n",
    "处理结构化数据，用logistic回归对结构化数据简单分类\n",
    "\n",
    "## 3.1.1 logistic回归介绍\n",
    "\n",
    "logistic回归是一种广义线性回归（generalized linear model），与多重线性回归分析有很多相同之处。\n",
    "模型形式基本相同，都具有wx + b，w和b是待求参数。区别在于因变量不同，多重线性回归直接将wx+b作为因变量，即y=wx+b。\n",
    "而logistic回归通过函数*L*将  wx+b对应p=L(wx+b), 根据p与1-p的大小决定因变量的值。\n",
    "如果L是logistic函数就是logistic回归，如果L是多项式函数就是多项式回归。\n",
    "\n",
    "logistic回归在线性回归后再调用一层logistic函数。\n",
    "logistic回归主要进行二分类预测，Sigmod函数是最常见的logistic函数。\n",
    "因为Sigmod函数输出0~1间的概率值，概率大于0.5预测为1，小于0.5预测为0。\n",
    "\n",
    "下面使用公开数据进行介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 UCI German Credit  数据集\n",
    "\n",
    "UCI German Credit是UCI德国信用数据集，里面有原数据和数值化后的数据。\n",
    "\n",
    "German Credit数据集根据个人银行**贷款信息**和申请客户**贷款逾期**情况预测**贷款违约倾向**，\n",
    "包含24维的1000条数据，用处理好的数值化数据展示。\n",
    "[地址](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 代码实战\n",
    "german.data-numeric是numpy处理好的数值化数据，直接用numpy的load方法读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"german.data-numeric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读取完成后对数据做归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1., 24.,  3., 49.,  1.,  3.,  3.,  4.,  4., 53.,  3.,  2.,  2.,\n",
       "        1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, l = data.shape\n",
    "print(n, l)\n",
    "data[:5][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(l - 1):\n",
    "    meanVal = np.mean(data[:, j])\n",
    "    stdVal = np.std(data[:, j])\n",
    "    data[:, j] = (data[:, j] - meanVal) / stdVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打乱数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "区分训练集和测试集，没有验证集，使用测试集准确度作为评判好坏标准\n",
    "\n",
    "800条用于训练，200条作为测试\n",
    "\n",
    "german.data-numeric格式: 前24列为24个维度，最后一个为标签（0，1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data[:800, :l - 1]\n",
    "train_label = data[:800, l - 1] - 1\n",
    "\n",
    "test_data = data[800:, :l - 1]\n",
    "test_label = data[800:, l - 1] - 1\n",
    "\n",
    "train_label[:5].dtype\n",
    "test_label[:5].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR, self).__init__()\n",
    "        # 由于24个维度已经固定，这里写24\n",
    "        self.fc = nn.Linear(24, 2)  \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pred, label):\n",
    "    t = pred.max(-1)[1] == label\n",
    "    return torch.mean(t.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LR()\n",
    "\n",
    "# CrossEntropyLoss损失\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam优化\n",
    "optm = torch.optim.Adam(net.parameters())\n",
    "# optm = torch.optim.RMSprop(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:500,Loss:0.503469,Accuracy：0.775000\n",
      "Epoch:1000,Loss:0.502480,Accuracy：0.770000\n",
      "Epoch:1500,Loss:0.501607,Accuracy：0.770000\n",
      "Epoch:2000,Loss:0.500800,Accuracy：0.770000\n",
      "Epoch:2500,Loss:0.500053,Accuracy：0.775000\n",
      "Epoch:3000,Loss:0.499360,Accuracy：0.775000\n",
      "Epoch:3500,Loss:0.498713,Accuracy：0.775000\n",
      "Epoch:4000,Loss:0.498110,Accuracy：0.775000\n",
      "Epoch:4500,Loss:0.497544,Accuracy：0.775000\n",
      "Epoch:5000,Loss:0.497014,Accuracy：0.775000\n"
     ]
    }
   ],
   "source": [
    "# 输入值转化成torch的Tensor\n",
    "X_train = torch.from_numpy(train_data).float()\n",
    "y_train = torch.from_numpy(train_label).long()\n",
    "\n",
    "X_test = torch.from_numpy(test_data).float()\n",
    "y_test = torch.from_numpy(test_label).long()\n",
    "\n",
    "# 训练5000次\n",
    "epochs = 5000\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    # 指定模型为训练模式，计算梯度\n",
    "    net.train()\n",
    "    y_hat = net(X_train)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = criterion(y_hat, y_train)\n",
    "\n",
    "    # 前一步的损失清零\n",
    "    optm.zero_grad()\n",
    "\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    # 优化\n",
    "    optm.step()\n",
    "\n",
    "    # 每100次输出相关信息\n",
    "    if (i + 1) % 500 == 0:\n",
    "\n",
    "        # 指定模型为计算模式\n",
    "        net.eval()\n",
    "        y_pred = net(X_test)\n",
    "\n",
    "        # 计算准确率\n",
    "        accu = test(y_pred, y_test)\n",
    "        print(\"Epoch:%d,Loss:%4f,Accuracy：%2f\" % (i + 1, loss.item(), accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完成,准确度达到78%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
